{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ValuablesNLP.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMODoBWRCKqC"
      },
      "source": [
        "The following two cells are required to download and load the model in to the system."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFAoZkN2pDUF"
      },
      "source": [
        "!gzip -d GoogleNews-vectors-negative300.bin.gz"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYQmDCuBiNo8",
        "outputId": "54553131-7ba5-4ded-916a-e57c551c54a9"
      },
      "source": [
        "!wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-08 19:44:48--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.88.134\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.88.134|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1647046227 (1.5G) [application/x-gzip]\n",
            "Saving to: ‘GoogleNews-vectors-negative300.bin.gz’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.53G  67.3MB/s    in 26s     \n",
            "\n",
            "2021-07-08 19:45:14 (60.4 MB/s) - ‘GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMO5KWDesD4m"
      },
      "source": [
        "# this function works without ML model\n",
        "def getWordsAssiciatedWithUser(userName, returnTopThree = False):\n",
        "  \"\"\"\n",
        "  Input:\n",
        "    - UserName or the userID in the data base\n",
        "    - returnTopthree (true or false)\n",
        "  Output:\n",
        "    - if only one word is required, return the most frequent word associated with a user\n",
        "    - if top three words are required, return the top three words associated with a profile\n",
        "  functionality:\n",
        "    - Access the database to get the user details\n",
        "    - count the words associated with a user profile \n",
        "    - return the most frequent word associated with a user profile\n",
        "  \"\"\"\n",
        "  #imports\n",
        "  from collections import Counter\n",
        "\n",
        "\n",
        "  #Currently using a dummy dataset\n",
        "  userDictionary  = {\"Alex\":'hard working,dedicated,responsible,dedicated','Tim':'hard working,dedicated,responsible,dedicated'}\n",
        "  \n",
        "\n",
        "  ''' The database \n",
        "        - we can use this as the data storage format in the database \n",
        "        - we can have the userID associated with the words\n",
        "        - while entering the data, we can ensure this format follows\n",
        "        - whenver the new data is added, we can append the new value with a comma (,) to the existing values\n",
        "  '''\n",
        "  #To Add: The database connection \n",
        "\n",
        "  #To Add: The data retrieval logic for a specific user\n",
        "\n",
        "  #Optional: We can use the NLTK to remove the stopwords, but since, we get only single words, it may not be required\n",
        "\n",
        "  #Once we access the data\n",
        "  currUserListOfWords = Counter(list(userDictionary[userName].split(\",\")))\n",
        "\n",
        "  # checking if more than one words for a profile are required\n",
        "\n",
        "  if returnTopThree:\n",
        "    #gets the top three most frequent words associated with a profile\n",
        "    wordsFrequency = list(currUserListOfWords.items())\n",
        "    wordsFrequency.sort(key=lambda x: x[1])\n",
        "    topThreeWords = ' '.join([i[0] for i in wordsFrequency[:3]])\n",
        "    return topThreeWords\n",
        "  else:\n",
        "    #returns the top most word associated with a profile\n",
        "    return max(currUserListOfWords)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "rrYpCAX-2gY5",
        "outputId": "9907a5ad-803e-4558-f957-ef9b60270d32"
      },
      "source": [
        "getWordsAssiciatedWithUser('Alex')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'responsible'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJVKWErcCVVm"
      },
      "source": [
        "The following cells describe various functions used to get the word asssociated with a profile, using a trained word2vec model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMm_RX-4p0rU"
      },
      "source": [
        "def getCleanWord(word,model):\n",
        "  \"\"\"\n",
        "  Input:\n",
        "    - word for which the embeddings are required\n",
        "  Output:\n",
        "    - punctuation removed word if it is present in model vocab; else None\n",
        "  functionality:\n",
        "    - removes any stop words\n",
        "    - spelling correction \n",
        "    - if the word is present in model vocabolary, return it\n",
        "  \"\"\"\n",
        "  import re\n",
        "  word = ''.join(list(re.sub(r'[^\\w\\s]','',word).split(\" \")))\n",
        "  if word in model.vocab:\n",
        "    return word\n",
        "  else:\n",
        "    #spelling correction can be implemented here\n",
        "    return None\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCm8j2Hval1o"
      },
      "source": [
        "def loadModel(modelBinaryPath = 'GoogleNews-vectors-negative300.bin.gz'):\n",
        "  \"\"\"\n",
        "  Input:\n",
        "   - file path of the model\n",
        "  Output:\n",
        "   - Model loaded from the file path\n",
        "  \"\"\"\n",
        "  import gensim\n",
        "  try:\n",
        "    model = gensim.models.KeyedVectors.load_word2vec_format(modelBinaryPath, binary = True)\n",
        "    return model\n",
        "  except:\n",
        "    return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1MV1S4dcW9Z"
      },
      "source": [
        "def getSimilarityScore(word1, word2, model):\n",
        "  \"\"\"\n",
        "  Input:\n",
        "    - both the words between whom the similarity is to be checked.\n",
        "    - WOrd2vec model to obtain the embedding of both the words.\n",
        "  Output:\n",
        "    - similarity score between both the words.\n",
        "  \"\"\"\n",
        "  if not word1 in model.vocab:\n",
        "    word1 = getCleanWord(word1,model)\n",
        "  if not word2 in model.vocab:\n",
        "    word2 = getCleanWord(word2,model)\n",
        "\n",
        "  if word1 == None or word2 == None:\n",
        "    return 0\n",
        "  else:\n",
        "    return model.similarity(word1,word2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSdJIpoSrMur"
      },
      "source": [
        "def getWordsAsscoiatedWithTheUser(User,model):\n",
        "  \"\"\"\n",
        "  Input:\n",
        "    - UserName or the userID in the data base,\n",
        "    - Word2vec model \n",
        "  Output:\n",
        "    - if only one word is required, return the most frequent word associated with a user\n",
        "  functionality:\n",
        "    - Access the database to get the user details\n",
        "    - count the words associated with a user profile \n",
        "    - return the most frequent word associated with a user profile based on word similarity\n",
        "  \"\"\"\n",
        "  from collections import Counter\n",
        "  #Currently using a dummy dataset\n",
        "  userDictionary  = {\"Alex\":'hard working,dedicated,responsible,dedicated','Tim':'hard working,dedicated,responsible,dedicated'}\n",
        "\n",
        "  #To Add: The database connection \n",
        "\n",
        "  #To Add: The data retrieval logic for a specific user\n",
        "\n",
        "  #Once we access the data\n",
        "  model = loadModel()\n",
        "  currUserListOfWords = list(userDictionary[User].split(\",\"))\n",
        "  wordfrequencies = Counter(currUserListOfWords)\n",
        "  currUserListOfWords = list(set(currUserListOfWords))\n",
        "  succesiveUserlistOfWords = iter(currUserListOfWords)\n",
        "  next(succesiveUserlistOfWords)\n",
        "  simScoreList = []\n",
        "  for i in range(len(currUserListOfWords)):\n",
        "    for j in range(len(succesiveUserlistOfWords)):\n",
        "      \n",
        "      simScore = getSimilarityScore(currUserListOfWords[i],succesiveUserlistOfWords[j],model)\n",
        "      if simScore > 0.4:\n",
        "        wordfrequencies[currUserListOfWords[i]] += 1\n",
        "\n",
        "  return max(wordfrequencies)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}